{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kN7S-hmpvSV2"
   },
   "source": [
    "# <b>CS156 (Introduction to AI), Spring 2022</b>\n",
    "# <u><b>Final term project</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC9EaypFvSV4"
   },
   "source": [
    "### Roster Name: Andy\n",
    "### Student ID: 014222676\n",
    "### Email address: andy.v.luong@sjsu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wcxf01uMvSV4"
   },
   "source": [
    "##  <u> Project description/introduction text (the background information) </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi5ZHa0BvSV4"
   },
   "source": [
    "Add the description of this project. Describe the background of the problem your project is trying to solve. Describe the ML problem you are solving below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BbRXJqLvSV4"
   },
   "source": [
    "##  <u> Machine learning algorithm selected for this project </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVTKKxMkvSV4"
   },
   "source": [
    "Name and add short description of the algorithm used for this project. You can re-use this text in your final poster submission.\n",
    "Decision Tree & Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLu1px9AvSV5"
   },
   "source": [
    "##  <u> Dataset source </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aq3h8kskvSV5"
   },
   "source": [
    "List the source from where the dataset for this project was obtained.\n",
    "https://www.kaggle.com/competitions/titanic/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_XfyhC6vSV5"
   },
   "source": [
    "##  <u> References and sources </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MHngxMTvSV5"
   },
   "source": [
    "List all your references and sources here.\n",
    "This includes all sites/discussion boards/blogs/posts/etc. where you grabbed some code examples.\n",
    "IF/ELSE All Values = https://stackoverflow.com/questions/44991438/lambda-including-if-elif-else\n",
    "Map = https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html\n",
    "PLT & SNS = #https://machinelearningknowledge.ai/seaborn-heatmap-using-sns-heatmap-with-examples-for-beginners/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQCMA2gLvSV5"
   },
   "source": [
    "##  <u>Solution</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12nKyfFFvSV6"
   },
   "source": [
    "#### Load libraries and set random number generator seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzIjjSnJvSV6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree #tree\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0TjQmyvvSV6"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eISqgIvivSV7"
   },
   "source": [
    "#### Code the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4eusdpI2gWw"
   },
   "source": [
    "###Making Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "J8ZDFAAEvSV7",
    "outputId": "99208319-8203-477a-d8d0-23c347710fc0"
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "import io\n",
    "train = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
    "uploaded2 = files.upload()\n",
    "import io\n",
    "test = pd.read_csv(io.BytesIO(uploaded2['test.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fcEmjXDvSV7"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFZxy4VAvSV7"
   },
   "outputs": [],
   "source": [
    "test.head() #test does not know who survives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-169Ms-HNrA"
   },
   "source": [
    "###Add Columns, Fix Nulls, Remove Unnecessary Variables, & Plot Seaborne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FkL8aQGHaMu"
   },
   "outputs": [],
   "source": [
    "train2 = train.copy()\n",
    "test2 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMBbGi8yHiao"
   },
   "outputs": [],
   "source": [
    "train = train2.copy()\n",
    "test = test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6Sq6ehf291o"
   },
   "outputs": [],
   "source": [
    "#Adds a column where...\n",
    "#value is 1 if there is a cabin, 0 otherwise\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "#it combines SibSp and Parch to find family size\n",
    "train['Family_Size'] = train['SibSp'] + train['Parch'] + 1\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoB9_zH_8Iwb"
   },
   "outputs": [],
   "source": [
    "#Replaces Null Values in Embarked, Fare, & Age With the Average Value\n",
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvqrmZy9zXuG"
   },
   "outputs": [],
   "source": [
    "# Map Sex\n",
    "if (train['Sex'][0] != 0) and (train['Sex'][0] != 1):\n",
    "  train['Sex'] = train['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Map Embarked\n",
    "if (train['Embarked'][0] != 0) and (train['Embarked'][0] != 1) and (train['Embarked'][0] != 2):\n",
    "  train['Embarked'] = train['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "# Map Fare\n",
    "fare_min = train['Fare'].min()\n",
    "fare_q1 = train['Fare'].quantile(.25)\n",
    "fare_median = train['Fare'].median()\n",
    "fare_q3 = train['Fare'].quantile(.75)\n",
    "fare_max = train['Fare'].max()\n",
    "fare_min, fare_q1, fare_median, fare_q3, fare_max\n",
    "\n",
    "train.loc[(train['Fare'] >= fare_min) & (train['Fare'] <= fare_q1), 'Fare'] = 0\n",
    "train.loc[(train['Fare'] > fare_q1) & (train['Fare'] < fare_median), 'Fare'] = 1\n",
    "train.loc[(train['Fare'] > fare_median) & (train['Fare'] < fare_q3), 'Fare'] = 2\n",
    "train.loc[(train['Fare'] >= fare_q3) & (train['Fare'] <= fare_max), 'Fare'] = 3\n",
    "    \n",
    "# Map Age\n",
    "age_min = train['Age'].min()\n",
    "age_q1 = train['Age'].quantile(.25)\n",
    "age_median = train['Age'].median()\n",
    "age_q3 = train['Age'].quantile(.75)\n",
    "age_max = train['Age'].max()\n",
    "age_min, age_q1, age_median, age_q3, age_max\n",
    "\n",
    "train.loc[(train['Age'] >= age_min) & (train['Age'] <= age_q1), 'Age'] = 0\n",
    "train.loc[(train['Age'] > age_q1) & (train['Age'] < age_median), 'Age'] = 1\n",
    "train.loc[(train['Age'] > age_median) & (train['Age'] < age_q3), 'Age'] = 2\n",
    "train.loc[(train['Age'] >= age_q3) & (train['Age'] <= age_max), 'Age'] = 3\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEjo7bn2DMRl"
   },
   "outputs": [],
   "source": [
    "#Drop columns that are not needed in calculation\n",
    "try:\n",
    "  dropColumns = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "  train = train.drop(dropColumns, axis = 1)\n",
    "  train\n",
    "except:\n",
    "  print(\"Already Dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu8VBfAtvSV7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Seaborn Heatmap of Dependent Variables')\n",
    "sns.heatmap(train.astype(float).corr(),linewidths=0.6, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJMN0HsTUy95"
   },
   "source": [
    "###Survival Rate For Each Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hO-vq6dZqwv"
   },
   "outputs": [],
   "source": [
    "#mean = survival rate, count = total people, sum = survivors\n",
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kqdb3GKhVNml"
   },
   "outputs": [],
   "source": [
    "#mean = survival rate, count = total people, sum = survivors\n",
    "train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRG7nIYqZcXY"
   },
   "outputs": [],
   "source": [
    "train[['Age', 'Survived']].groupby(['Age'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YAcnkkfZj6M"
   },
   "outputs": [],
   "source": [
    "train[['Age', 'Survived']].groupby(['Age'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCORPPZ_ZkFH"
   },
   "outputs": [],
   "source": [
    "train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "My8U4E6laOxC"
   },
   "outputs": [],
   "source": [
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGm3q26baO3v"
   },
   "outputs": [],
   "source": [
    "train[['Has_Cabin', 'Survived']].groupby(['Has_Cabin'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U-yGfd_qaeGs"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFamily_Size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFamily_Size\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train[['Family_Size', 'Survived']].groupby(['Family_Size'], as_index=False).agg(['mean', 'count', 'sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OObAmPsAWTY3"
   },
   "source": [
    "###Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8mD-HhSWVtS"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10)            # Desired number of Cross Validation folds\n",
    "accuracies = list()\n",
    "max_attributes = len(list(test))\n",
    "depth_range = range(1, max_attributes + 1)\n",
    "\n",
    "# Testing max_depths from 1 to max attributes\n",
    "# Uncomment prints for details about each Cross Validation pass\n",
    "for depth in depth_range:\n",
    "    fold_accuracy = []\n",
    "    tree_model = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "    # print(\"Current max depth: \", depth, \"\\n\")\n",
    "    for train_fold, valid_fold in cv.split(train):\n",
    "        f_train = train.loc[train_fold] # Extract train data with cv indices\n",
    "        f_valid = train.loc[valid_fold] # Extract valid data with cv indices\n",
    "\n",
    "        model = tree_model.fit(X = f_train.drop(['Survived'], axis=1), \n",
    "                               y = f_train[\"Survived\"]) # We fit the model with the fold train data\n",
    "        valid_acc = model.score(X = f_valid.drop(['Survived'], axis=1), \n",
    "                                y = f_valid[\"Survived\"])# We calculate accuracy with the fold validation data\n",
    "        fold_accuracy.append(valid_acc)\n",
    "\n",
    "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
    "    accuracies.append(avg)\n",
    "    # print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "    # print(\"Average accuracy: \", avg)\n",
    "    # print(\"\\n\")\n",
    "    \n",
    "# Just to show results conveniently\n",
    "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
    "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEOcEygjYD-h"
   },
   "outputs": [],
   "source": [
    "#Do the same for test\n",
    "#Adds a column where...\n",
    "#value is 1 if there is a cabin, 0 otherwise\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "#it combines SibSp and Parch to find family size\n",
    "test['Family_Size'] = test['SibSp'] + test['Parch'] + 1\n",
    "#Replaces Null Values in Embarked, Fare, & Age With the Average Value\n",
    "test['Embarked'] = test['Embarked'].fillna('S')\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "test\n",
    "#Replaces Null Values in Embarked, Fare, & Age With the Average Value\n",
    "test['Embarked'] = test['Embarked'].fillna('S')\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "test\n",
    "# Map Sex\n",
    "if (test['Sex'][0] != 0) and (test['Sex'][0] != 1):\n",
    " test['Sex'] = test['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    " \n",
    "# Map Embarked\n",
    "if (test['Embarked'][0] != 0) and (test['Embarked'][0] != 1) and (test['Embarked'][0] != 2):\n",
    " test['Embarked'] = test['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "  \n",
    "# Map Fare\n",
    "fare_min = test['Fare'].min()\n",
    "fare_q1 = test['Fare'].quantile(.25)\n",
    "fare_median = test['Fare'].median()\n",
    "fare_q3 = test['Fare'].quantile(.75)\n",
    "fare_max = test['Fare'].max()\n",
    "fare_min, fare_q1, fare_median, fare_q3, fare_max\n",
    " \n",
    "test.loc[(test['Fare'] >= fare_min) & (test['Fare'] <= fare_q1), 'Fare'] = 0\n",
    "test.loc[(test['Fare'] > fare_q1) & (test['Fare'] < fare_median), 'Fare'] = 1\n",
    "test.loc[(test['Fare'] > fare_median) & (test['Fare'] < fare_q3), 'Fare'] = 2\n",
    "test.loc[(test['Fare'] >= fare_q3) & (test['Fare'] <= fare_max), 'Fare'] = 3\n",
    "  \n",
    "# Map Age\n",
    "age_min = test['Age'].min()\n",
    "age_q1 = test['Age'].quantile(.25)\n",
    "age_median = test['Age'].median()\n",
    "age_q3 = test['Age'].quantile(.75)\n",
    "age_max = test['Age'].max()\n",
    "age_min, age_q1, age_median, age_q3, age_max\n",
    " \n",
    "test.loc[(test['Age'] >= age_min) & (test['Age'] <= age_q1), 'Age'] = 0\n",
    "test.loc[(test['Age'] > age_q1) & (test['Age'] < age_median), 'Age'] = 1\n",
    "test.loc[(test['Age'] > age_median) & (test['Age'] < age_q3), 'Age'] = 2\n",
    "test.loc[(test['Age'] >= age_q3) & (test['Age'] <= age_max), 'Age'] = 3\n",
    "test\n",
    "#Drop columns that are not needed in calculation\n",
    "try:\n",
    " dropColumns = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    " test = test.drop(dropColumns, axis = 1)\n",
    " test\n",
    "except:\n",
    " print(\"Already Dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BdqnS0TXA6i"
   },
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target (Survived) dataframes to feed into our models\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "y_train = train['Survived']\n",
    "x_train = train.drop(['Survived'], axis=1).values \n",
    "x_test = test.values\n",
    "\n",
    "# Create Decision Tree with max_depth = 3\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# Predicting results for test dataset\n",
    "PassengerId = test2['PassengerId']\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Export our trained model as a .dot file\n",
    "with open(\"tree1.dot\", 'w') as f:\n",
    "     f = tree.export_graphviz(decision_tree,\n",
    "                              out_file=f,\n",
    "                              max_depth = 3,\n",
    "                              impurity = True,\n",
    "                              feature_names = list(train.drop(['Survived'], axis=1)),\n",
    "                              class_names = ['Died', 'Survived'],\n",
    "                              rounded = True,\n",
    "                              filled= True )\n",
    "        \n",
    "#Convert .dot to .png to allow display in web notebook\n",
    "check_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n",
    "\n",
    "# Annotating chart with PIL\n",
    "img = Image.open(\"tree1.png\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', 26)\n",
    "draw.text((10, 0), # Drawing offset (position)\n",
    "          '\"Title <= 1.5\" corresponds to \"Mr.\" title', # Text to draw\n",
    "          (0,0,255), # RGB desired color\n",
    "          font=font) # ImageFont object with desired font\n",
    "img.save('sample-out.png')\n",
    "PImage(\"sample-out.png\")\n",
    "\n",
    "# Code to check available fonts and respective paths\n",
    "# import matplotlib.font_manager\n",
    "# matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f1gHaJZY6m2"
   },
   "outputs": [],
   "source": [
    "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TermProjectSubmission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
